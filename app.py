from flask import Flask, render_template, request, session, jsonify
import openai
import os
import logging

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ API ã‚­ãƒ¼ã‚’å–å¾—
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.DEBUG)

app = Flask(__name__)
app.secret_key = "supersecretkey"



# è³ªå•ãƒªã‚¹ãƒˆ
questions = [
    {
        "question": "å±…ä½ç’°å¢ƒã‚’æ•™ãˆã¦ãã ã•ã„",
        "choices": ["ä¸€æˆ¸å»ºã¦", "é›†åˆä½å®…(å˜èº«å‘ã‘)", "é›†åˆä½å®…(å®¶æ—å‘ã‘)"]
    },
    {
        "question": "å®¶æ—æ§‹æˆã‚’æ•™ãˆã¦ãã ã•ã„",
        "choices": ["ä¸€äººæš®ã‚‰ã—", "æ—¢å©š(å­ã©ã‚‚ç„¡ã—)", "æ—¢å©š(å­ã©ã‚‚æœ‰ã‚Š)"]
    },
    {
        "question": "ä¸»ã«ä¸–è©±ã‚’ã™ã‚‹æ–¹ã®å¹´é½¢ã¯ï¼Ÿ",
        "choices": ["ï½22æ­³", "23æ­³ï½35æ­³", "36æ­³ï½60æ­³", "61æ­³ï½"]
    },
    {
        "question": "çŠ¬ã«æ±‚ã‚ã‚‹æ€§æ ¼ã¯ï¼Ÿ",
        "choices": ["ç©ã‚„ã‹ã§è½ã¡ç€ã„ã¦ã„ã‚‹", "æ´»ç™ºã§éŠã³å¥½ã", "è­¦æˆ’å¿ƒãŒå¼·ãç•ªçŠ¬å‘ã"]
    },
    {
        "question": "é£¼ã„ãŸã„ã‚µã‚¤ã‚ºã¯ï¼Ÿ",
        "choices": ["å°å‹çŠ¬ï¼ˆ10kgæœªæº€ï¼‰", "ä¸­å‹çŠ¬ï¼ˆ10kgä»¥ä¸Š25kgæœªæº€ï¼‰", "å¤§å‹çŠ¬ï¼ˆ25kgä»¥ä¸Šï¼‰"]
    },
    {
        "question": "å¸Œæœ›ã™ã‚‹æ‰‹å…¥ã‚Œã®é »åº¦ã¯ï¼Ÿ",
        "choices": ["æ¯æœˆã‚µãƒ­ãƒ³ã§ã®ãƒˆãƒªãƒŸãƒ³ã‚°ãŒå¯èƒ½", "é€±ã«æ•°å›ã®ãƒ–ãƒ©ãƒƒã‚·ãƒ³ã‚°ãŒå¯èƒ½", "ã§ãã‚‹ã ã‘æ‰‹å…¥ã‚ŒãŒå°‘ãªã„"]
    },
    {
        "question": "1æ—¥ã«çŠ¬ã¨éã”ã›ã‚‹å¹³å‡æ™‚é–“ã¯ï¼Ÿ",
        "choices": ["1ï½2æ™‚é–“", "2ï½4æ™‚é–“", "4æ™‚é–“ä»¥ä¸Š"]
    },
    {
        "question": "æ¯æ—¥ã®æ•£æ­©ã§æ­©ã‘ã‚‹æ™‚é–“ã¯ï¼Ÿ",
        "choices": ["30åˆ†ä»¥å†…", "30åˆ†ï½1æ™‚é–“", "1æ™‚é–“ä»¥ä¸Š"]
    }
]

@app.route("/")
def home():
    session.clear()
    session["answers"] = []
    session["current_question"] = 0
    return render_template("chat.html")

@app.route("/next_question", methods=["POST"])
def next_question():
    user_answer = request.json.get("answer")
    if user_answer:
        session["answers"].append(user_answer)
    question_index = session["current_question"]
    if question_index < len(questions):
        session["current_question"] += 1
        return jsonify({
            "question": questions[question_index]["question"],
            "choices": questions[question_index]["choices"]
        })
    else:
        return jsonify({"end": True})

@app.route("/get_recommendation", methods=["POST"])
def get_recommendation():
    user_answers = session.get("answers", [])

    prompt = f"ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€é©ã—ãŸçŠ¬ç¨®ã‚’2ã¤ææ¡ˆã—ã¦ãã ã•ã„:\n{user_answers}"

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯çŠ¬ç¨®è¨ºæ–­ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600,
            temperature=0.7
        )
        result_text = response.choices[0].message.content.strip()

    except Exception as e:
        logging.error(f"OpenAI API ã‚¨ãƒ©ãƒ¼: {str(e)}")
        result_text = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

    return jsonify({"result": result_text, "prompt": prompt})

# ğŸš€ Railway ã§ PORT ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
